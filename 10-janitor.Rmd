# Data Cleaning Part II: Janitor

The bane of every data analyst's existence is data cleaning. 

Every developer, every data system, every agency, the all have opinions about how data gets collected. Some decisions make sense from the outside. Some decisions are based entirely on internal politics: who is creating the data, how they are creating it, why they are creating it. Is it automated? Is it manual? Are data normalized? Are there free form fields where users can just type into or does the system restrict them to choices? 

Your question -- what you want to do with the data -- is almost never part of that equation. 

So cleaning data is the process of fixing issues in your data so you can answer the questions you want to answer. Data cleaning is a critical step that you can't skip past. A standard metric is that 80 percent of the time working with data will be spent cleaning and verifying data, and 20 percent the more exciting parts like analysis and visualization.  

The tidyverse has a lot of built-in tools for data cleaning.  We're also going to make use of a new library, called `janitor` that has a bunch of great functions for cleaning data.  Let's load those now. 

```{r}
library(tidyverse)
library(janitor)
```

Now let's load a tiny slice of our Maryland PPP loan dataset. To make the cleaning demonstration in this chapter easier, this dataset only has six rows and seven columns, all from Arnold, Maryland.  

```{r}
arnold_md_loans <- read_rds("data/ppp_loan_data/processed/md/arnold_md_loans.rmd")
```

Let's glimpse it to get a sense of it. 

```{r}
glimpse(arnold_md_loans)
```

And let's examine the full data set. 

```{r}
arnold_md_loans
```

There are a number of issues with this data set. They are:
* The column headers are inconsistently styled.  The first column "1_id" starts with a number. The "NAME" column is all caps, while the rest are lowercase. And "street address" has a space in it. Those problems will make them hard to analyze. 
* The amount column is stored as a character, not a number. If we try to do math to it -- say, calculate the average loan size -- it won't work. 
* There's a fully duplicated row -- a common problem in data sets.  The first row is exactly the same as the second. 
* The city field has five different forms -- including misspellings -- of Arnold. If we wanted to group and count the number of loans in Arnold, this inconsistency would not let us do that correctly. 
* The zip field mixes five digit ZIP codes and nine digit ZIP codes.  If we wanted to group and count the number of loans in a given ZIP code, this inconsistency would not let us do that correctly. 
* The street address field is inconsistent. It has multiple variations of Ritchie Hwy. 

Let's get cleaning.  Our goal will be to build up one block of code that does all the necessary cleaning in order to answer this question: what is the total amount of loans made to businesses in Arnold, MD in ZIP code 21012.   

## Cleaning headers

One of the first places we can start with cleaning data is cleaning the column names (or headers). 

Every system has their own way of recording headers, and every developer has their own thoughts of what a good idea is within it. R is most happy when headers are lower case, without special characters. 

If column headers start with a number, or have a space in between two words, you have to set them off with backticks when using them in a function. Generally speaking, we want one word (or words separated by an underscore), all lowercase, that don't start with numbers.  

The `janitor` library makes fixing headers trivially simple with the function `clean_names()`

```{r}
# cleaning function
cleaned_arnold_md_loans <- arnold_md_loans %>%
  clean_names()

# display the cleaned dataset
cleaned_arnold_md_loans

  
```

This function changed `NAME` to `name`.  It put an underscore in `street_address` to get rid of the space.  And it changed `1_id` to `x1_id`. That last one was an improvement -- it no longer starts with a number, but it's still kind of clunky. 

We can use a tidyverse function ``rename` to fix that. Let's just call it `id` 

```{r}
# cleaning function
cleaned_arnold_md_loans <- arnold_md_loans %>%
  clean_names() %>%
  rename(id = x1_id)

# display the cleaned dataset
cleaned_arnold_md_loans

  
```

## Changing data types

Right now, the amount column is stored as a character.  Do you see the little `<chr>` under the amount column in the table above?  If we wanted to do math to it, we'd get an error, like so. 

```{r}
# cleaning function
total_arnold_md_loans <- cleaned_arnold_md_loans %>%
  summarise(total_amount = sum(amount))

# display the cleaned dataset
total_arnold_md_loans

  
```

We got an "invalid 'type' (character)" error.  So let's fix that using the mutate() function in concert with as.numeric().  We'll reuse the same column name, so it overwrites it.  

```{r}
# cleaning function
cleaned_arnold_md_loans <- arnold_md_loans %>%
  clean_names() %>%
  rename(id = x1_id) %>%
  mutate(amount = as.numeric(amount))
  

# display the cleaned dataset
cleaned_arnold_md_loans

```

Notice that the amount has been converted to a `<dbl>`, which is short for double, a number format.  When we attempt to add up all of the amounts to create a total, this time it works fine. 

```{r}
# cleaning function
total_arnold_md_loans <- cleaned_arnold_md_loans %>%
  summarise(total_amount = sum(amount))

# display the cleaned dataset
total_arnold_md_loans

  
```
## Duplicates

One of the most difficult problems to fix in data is duplicates in the data. They can creep  in with bad joins, bad data entry practices, mistakes -- all kinds of reasons. A duplicated record isn't always there because of an error, but you need to know if it's there before making that determination.
So the question is, do we have any records repeated? 

Here we'll use a function called `get_dupes` from the janitor library to check for fully repeated records in our cleaned data set.   

```{r}
cleaned_arnold_md_loans %>% 
  get_dupes()
```

In this case, the first two records in our table are fully duplicated. Every field is identical in each. 

We can fix this by adding the function `distinct()` to our cleaning script.  This will keep only one copy of each unique record in our table 

```{r}
# cleaning function
cleaned_arnold_md_loans <- arnold_md_loans %>%
  clean_names() %>%
  rename(id = x1_id) %>%
  mutate(amount = as.numeric(amount)) %>%
  distinct()
  

# display the cleaned dataset
cleaned_arnold_md_loans

```

## Cleaning strings

The rest of the problems with this data set all have to do with inconsistent format of values that all represent essentially the same thing.  To fix these problems we're going to make use of mutate() and a new function, `case_when()` in concert with "string functions" -- special functions that allow us to clean up columns stored as character strings. The tidyverse package `stringr` has lots of useful string functions, more than we'll learn in this chapter. 

Let's start by cleaning up the zip field. Remember, three of rows had a five-digit ZIP code, while two had a nine-digit ZIP code, separated by a hyphen.
We're going to write code that tells R to keep the first five digits on the left, and get rid of anything after that by using `mutate()` in concert with `str_sub()`, from the `stringr` package. 

```{r}
# cleaning function
cleaned_arnold_md_loans <- arnold_md_loans %>%
  clean_names() %>%
  rename(id = x1_id) %>%
  mutate(amount = as.numeric(amount)) %>%
  distinct() %>%
  mutate(zip = str_sub(zip, start=1L, end=5L))
  

# display the cleaned dataset
cleaned_arnold_md_loans

```

This code says take the value in each ZIP column and extract the first character on the left (1L) through the fifth character on the left (5L), and then use that five-digit zip to overwrite the zip column. 

Now let's clean the city column to standardize how we spell Arnold. For that, we're going to use a few different functions.  Let's start by changing every value to title case -- first letter uppercase, subsequent letters lowercase -- using the `str_to_title()` function from `stringr`.  

```{r}
# cleaning function
cleaned_arnold_md_loans <- arnold_md_loans %>%
  clean_names() %>%
  rename(id = x1_id) %>%
  mutate(amount = as.numeric(amount)) %>%
  distinct() %>%
  mutate(zip = str_sub(zip, start=1L, end=5L)) %>%
  mutate(city = str_to_title(city))
  

# display the cleaned dataset
cleaned_arnold_md_loans

```

That was enough to standardize two values (ARNOLD and arnold).  The only ones that remain are the two clear misspellings (Arnld and Anold). To fix those, we're going to do some manual editing.  And for that, we're going to use `case_when()`, a function that let's us say if a value meets a certain condition, then change it, and if it doesn't, don't change it.   

```{r}
# cleaning function
cleaned_arnold_md_loans <- arnold_md_loans %>%
  clean_names() %>%
  rename(id = x1_id) %>%
  mutate(amount = as.numeric(amount)) %>%
  distinct() %>%
  mutate(zip = str_sub(zip, start=1L, end=5L)) %>%
  mutate(city = str_to_title(city)) %>%
  mutate(city = case_when(
    city == "Anold" ~ "Arnold",
    TRUE ~ city
  ))
  

# display the cleaned dataset
cleaned_arnold_md_loans

```

This is a little complex, so let's break it down.  What the code above says, in English, is this:  Look at all the values in the city column. If the value is "Anold", then (that's what the ~ means, then) replace it with the word "Arnold". If it's anything other than that (that's what TRUE means, otherwise), then keep the existing value in that column. 

We can fix "Arnld" by adding a line to that same function. 

```{r}
# cleaning function
cleaned_arnold_md_loans <- arnold_md_loans %>%
  clean_names() %>%
  rename(id = x1_id) %>%
  mutate(amount = as.numeric(amount)) %>%
  distinct() %>%
  mutate(zip = str_sub(zip, start=1L, end=5L)) %>%
  mutate(city = str_to_title(city)) %>%
  mutate(city = case_when(
    city == "Anold" ~ "Arnold",
    city == "Arnld" ~ "Arnold",
    TRUE ~ city
  ))
  

# display the cleaned dataset
cleaned_arnold_md_loans

```

Lastly, there's the issue with inconsistent spelling of Ritchie Hwy in the street address column.  Do we need to clean this? 

Remember the motivating question that's driving us to do this cleaning: What's the total amount of loans (at least in this tiny slice of data) for Arnold, MD in ZIP code 21012?

We don't need the street_address field to answer that question.  So we're not going to bother cleaning it.  That's a good approach for the future. A good rule of thumb is that you should only spend time cleaning fields that are critical to the specific analysis you want to do.  
